{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Easy or Hard?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import mlp\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# import data\n",
    "train_data = pd.read_csv('MNIST_train.csv', index_col='ID')\n",
    "val_data   = train_data[55000:]\n",
    "train_data = train_data[:55000]\n",
    "test_data  = pd.read_csv('MNIST_test.csv', index_col='ID')\n",
    "\n",
    "train_data_unlabeled = train_data.drop(' Label', axis=1)\n",
    "val_data_unlabeled   = val_data.drop(' Label', axis=1)\n",
    "test_data_unlabeled  = test_data.drop(' Label', axis=1)\n",
    "\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Naive statistical analysis**\n",
    "Here, we just compute:\n",
    "- prediction accuracy for each number, averaged over all algorithms\n",
    "- accuracy of each algorithm\n",
    "- accuracy of each algorithm for each number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>num_correct</th>\n",
       "      <td>18.862716</td>\n",
       "      <td>19.021732</td>\n",
       "      <td>17.844648</td>\n",
       "      <td>17.967983</td>\n",
       "      <td>18.147296</td>\n",
       "      <td>17.446101</td>\n",
       "      <td>18.50975</td>\n",
       "      <td>19.20221</td>\n",
       "      <td>17.26694</td>\n",
       "      <td>17.761068</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     0          1          2          3          4          5  \\\n",
       "num_correct  18.862716  19.021732  17.844648  17.967983  18.147296  17.446101   \n",
       "\n",
       "                    6         7         8          9  \n",
       "num_correct  18.50975  19.20221  17.26694  17.761068  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute average accuracy\n",
    "correct = train_data\n",
    "correct['num_correct'] = train_data_unlabeled.apply(lambda row: row.sum(),1)\n",
    "\n",
    "average_accuracy = pd.DataFrame(index=['num_correct'])\n",
    "for i in range(10):\n",
    "    average_accuracy[i] = correct.loc[correct[' Label'] == i]['num_correct'].mean()\n",
    "\n",
    "average_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The median accuracy is: 18.057639225541912\n",
      "The mean accuracy is:   18.203044416227115\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAD8CAYAAACcjGjIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAFDJJREFUeJzt3X+s3fV93/HnazZkUZIWEzxGbaemqbeJVCuhFqFrVrFk\nBUOmmkxRBpuKl6K6UUBKtE6r00qF5ccEm5JqdCkVGVZMlcWw/BhW4oy4DCnKHxAMMT8Mob4QELYM\nuJhAokjJTN/743zMTu7n3B/ce33PvfHzIR2d73l/P99z3ud7vz6v+/1xrlNVSJI07O+MuwFJ0tJj\nOEiSOoaDJKljOEiSOoaDJKljOEiSOoaDJKljOEiSOjOGQ5K/m+TbSR5Msj/Jf2z1s5Pcm2QiyW1J\nTm3117XHE23++qHn+mirP57k4qH6plabSLJt4d+mJOm1yEzfkE4S4A1V9cMkpwDfAj4M/Dvgy1W1\nM8lfAA9W1U1JPgT846r6YJLLgfdW1b9Kcg7wBeB84BeAvwL+QXuZvwZ+CzgI3AdcUVWPTtfXGWec\nUevXr5/bu5akk9T999//N1W1eqZxK2caUIP0+GF7eEq7FfAu4F+3+g7gOuAmYHObBvgi8N9awGwG\ndlbVj4HvJZlgEBQAE1X1JECSnW3stOGwfv169u7dO1P7kqQhSZ6ezbhZnXNIsiLJPuB5YA/wBPD9\nqjrWhhwE1rTpNcAzAG3+S8Cbh+uTlpmqLkkak1mFQ1W9UlXnAmsZ/Lb/j05oV1NIsjXJ3iR7jxw5\nMo4WJOmk8JquVqqq7wN3A78OnJbk+GGptcChNn0IWAfQ5v888MJwfdIyU9VHvf7NVbWxqjauXj3j\nITNJ0hzN5mql1UlOa9OvZ3Di+DEGIfG+NmwLcEeb3tUe0+b/n3beYhdwebua6WxgA/BtBiegN7Sr\nn04FLm9jJUljMuMJaeAsYEeSFQzC5Paq+mqSR4GdST4BfAe4pY2/BfjLdsL5KIMPe6pqf5LbGZxo\nPgZcXVWvACS5BrgTWAFsr6r9C/YOJUmv2YyXsi5VGzduLK9WkqTXJsn9VbVxpnF+Q1qS1DEcJEkd\nw0GS1JnNCWlJ+pm2ftvX5rTcU9e/Z4E7WTrcc5AkdQwHSVLHcJAkdQwHSVLHcJAkdQwHSVLHcJAk\ndQwHSVLHcJAkdQwHSVLHcJAkdQwHSVLHcJAkdQwHSVLHcJAkdQwHSVLHcJAkdQwHSVLHcJAkdQwH\nSVLHcJAkdQwHSVLHcJAkdWYMhyTrktyd5NEk+5N8uNWvS3Ioyb52u3RomY8mmUjyeJKLh+qbWm0i\nybah+tlJ7m3125KcutBvVJI0e7PZczgG/EFVnQNcAFyd5Jw270+r6tx22w3Q5l0OvA3YBPx5khVJ\nVgCfAS4BzgGuGHqeG9pz/TLwInDVAr0/SdIczBgOVXW4qh5o0z8AHgPWTLPIZmBnVf24qr4HTADn\nt9tEVT1ZVT8BdgKbkwR4F/DFtvwO4LK5viFJ0vy9pnMOSdYDbwfubaVrkjyUZHuSVa22BnhmaLGD\nrTZV/c3A96vq2KS6JGlMZh0OSd4IfAn4SFW9DNwEvBU4FzgMfOqEdPjTPWxNsjfJ3iNHjpzol5Ok\nk9aswiHJKQyC4fNV9WWAqnquql6pqr8FPsvgsBHAIWDd0OJrW22q+gvAaUlWTqp3qurmqtpYVRtX\nr149m9YlSXMwm6uVAtwCPFZVnx6qnzU07L3AI216F3B5ktclORvYAHwbuA/Y0K5MOpXBSetdVVXA\n3cD72vJbgDvm97YkSfOxcuYh/AbwO8DDSfa12h8xuNroXKCAp4DfB6iq/UluBx5lcKXT1VX1CkCS\na4A7gRXA9qra357vD4GdST4BfIdBGEmSxmTGcKiqbwEZMWv3NMt8EvjkiPruUctV1ZP8/8NSkqQx\n8xvSkqSO4SBJ6hgOkqSO4SBJ6hgOkqSO4SBJ6hgOkqSO4SBJ6hgOkqSO4SBJ6hgOkqSO4SBJ6hgO\nkqSO4SBJ6hgOkqSO4SBJ6hgOkqSO4SBJ6hgOkqSO4SBJ6hgOkqSO4SBJ6hgOkqSO4SBJ6hgOkqSO\n4SBJ6hgOkqTOjOGQZF2Su5M8mmR/kg+3+ulJ9iQ50O5XtXqS3JhkIslDSc4beq4tbfyBJFuG6r+W\n5OG2zI1JciLerCRpdmaz53AM+IOqOge4ALg6yTnANuCuqtoA3NUeA1wCbGi3rcBNMAgT4FrgHcD5\nwLXHA6WN+b2h5TbN/61JkuZqxnCoqsNV9UCb/gHwGLAG2AzsaMN2AJe16c3ArTVwD3BakrOAi4E9\nVXW0ql4E9gCb2ryfq6p7qqqAW4eeS5I0Bq/pnEOS9cDbgXuBM6vqcJv1LHBmm14DPDO02MFWm65+\ncERdkjQmsw6HJG8EvgR8pKpeHp7XfuOvBe5tVA9bk+xNsvfIkSMn+uUk6aQ1q3BIcgqDYPh8VX25\nlZ9rh4Ro98+3+iFg3dDia1ttuvraEfVOVd1cVRurauPq1atn07okaQ5mc7VSgFuAx6rq00OzdgHH\nrzjaAtwxVL+yXbV0AfBSO/x0J3BRklXtRPRFwJ1t3stJLmivdeXQc0mSxmDlLMb8BvA7wMNJ9rXa\nHwHXA7cnuQp4Gnh/m7cbuBSYAH4EfACgqo4m+ThwXxv3sao62qY/BHwOeD3w9XaTJI3JjOFQVd8C\npvrewbtHjC/g6imeazuwfUR9L/ArM/UiSVocfkNaktQxHCRJHcNBktQxHCRJHcNBktQxHCRJHcNB\nktQxHCRJHcNBktQxHCRJHcNBktQxHCRJHcNBktQxHCRJHcNBktQxHCRJHcNBktQxHCRJHcNBktQx\nHCRJHcNBktQxHCRJHcNBktQxHCRJHcNBktQxHCRJHcNBktSZMRySbE/yfJJHhmrXJTmUZF+7XTo0\n76NJJpI8nuTiofqmVptIsm2ofnaSe1v9tiSnLuQblCS9drPZc/gcsGlE/U+r6tx22w2Q5BzgcuBt\nbZk/T7IiyQrgM8AlwDnAFW0swA3tuX4ZeBG4aj5vSJI0fzOGQ1V9Ezg6y+fbDOysqh9X1feACeD8\ndpuoqier6ifATmBzkgDvAr7Ylt8BXPYa34MkaYHN55zDNUkeaoedVrXaGuCZoTEHW22q+puB71fV\nsUn1kZJsTbI3yd4jR47Mo3VJ0nTmGg43AW8FzgUOA59asI6mUVU3V9XGqtq4evXqxXhJSToprZzL\nQlX13PHpJJ8FvtoeHgLWDQ1d22pMUX8BOC3Jyrb3MDxekjQmc9pzSHLW0MP3AsevZNoFXJ7kdUnO\nBjYA3wbuAza0K5NOZXDSeldVFXA38L62/Bbgjrn0JElaODPuOST5AnAhcEaSg8C1wIVJzgUKeAr4\nfYCq2p/kduBR4BhwdVW90p7nGuBOYAWwvar2t5f4Q2Bnkk8A3wFuWbB3J0makxnDoaquGFGe8gO8\nqj4JfHJEfTewe0T9SQZXM0mSlgi/IS1J6hgOkqSO4SBJ6hgOkqSO4SBJ6hgOkqSO4SBJ6hgOkqSO\n4SBJ6hgOkqSO4SBJ6hgOkqSO4SBJ6hgOkqSO4SBJ6hgOkqSO4SBJ6hgOkqSO4SBJ6hgOkqSO4SBJ\n6hgOkqSO4SBJ6hgOkqSO4SBJ6hgOkqSO4SBJ6swYDkm2J3k+ySNDtdOT7ElyoN2vavUkuTHJRJKH\nkpw3tMyWNv5Aki1D9V9L8nBb5sYkWeg3KUl6bWaz5/A5YNOk2jbgrqraANzVHgNcAmxot63ATTAI\nE+Ba4B3A+cC1xwOljfm9oeUmv5YkaZHNGA5V9U3g6KTyZmBHm94BXDZUv7UG7gFOS3IWcDGwp6qO\nVtWLwB5gU5v3c1V1T1UVcOvQc0mSxmSu5xzOrKrDbfpZ4Mw2vQZ4ZmjcwVabrn5wRH2kJFuT7E2y\n98iRI3NsXZI0k3mfkG6/8dcC9DKb17q5qjZW1cbVq1cvxktK0klpruHwXDskRLt/vtUPAeuGxq1t\ntenqa0fUJUljtHKOy+0CtgDXt/s7hurXJNnJ4OTzS1V1OMmdwH8aOgl9EfDRqjqa5OUkFwD3AlcC\nfzbHniRpUa3f9rU5L/vU9e9ZwE4W3ozhkOQLwIXAGUkOMrjq6Hrg9iRXAU8D72/DdwOXAhPAj4AP\nALQQ+DhwXxv3sao6fpL7QwyuiHo98PV2kySN0YzhUFVXTDHr3SPGFnD1FM+zHdg+or4X+JWZ+pAk\nLR6/IS1J6hgOkqSO4SBJ6hgOkqSO4SBJ6hgOkqSO4SBJ6hgOkqSO4SBJ6hgOkqSO4SBJ6hgOkqSO\n4SBJ6hgOkqSO4SBJ6hgOkqSO4SBJ6hgOkqSO4SBJ6hgOkqSO4SBJ6qwcdwOStBDWb/vauFv4meKe\ngySpYzhIkjqGgySpYzhIkjrzCockTyV5OMm+JHtb7fQke5IcaPerWj1JbkwykeShJOcNPc+WNv5A\nki3ze0uSpPlaiD2Hf1ZV51bVxvZ4G3BXVW0A7mqPAS4BNrTbVuAmGIQJcC3wDuB84NrjgSJJGo8T\ncVhpM7CjTe8ALhuq31oD9wCnJTkLuBjYU1VHq+pFYA+w6QT0JUmapfmGQwHfSHJ/kq2tdmZVHW7T\nzwJntuk1wDNDyx5stanqkqQxme+X4N5ZVYeS/D1gT5LvDs+sqkpS83yNV7UA2grwlre8ZaGeVpI0\nybz2HKrqULt/HvgKg3MGz7XDRbT759vwQ8C6ocXXttpU9VGvd3NVbayqjatXr55P65Kkacw5HJK8\nIcmbjk8DFwGPALuA41ccbQHuaNO7gCvbVUsXAC+1w093AhclWdVORF/UapKkMZnPYaUzga8kOf48\n/6Oq/neS+4Dbk1wFPA28v43fDVwKTAA/Aj4AUFVHk3wcuK+N+1hVHZ1HX5KkeZpzOFTVk8Cvjqi/\nALx7RL2Aq6d4ru3A9rn2IklaWH5DWpLUMRwkSR3DQZLUMRwkSR3DQZLUMRwkSR3DQZLUMRwkSR3D\nQZLUMRwkSR3DQZLUMRwkSZ35/mc/krSg1m/72rhbEO45SJJGMBwkSR3DQZLUMRwkSR3DQZLUMRwk\nSR3DQZLU8XsOkjQGc/0+x1PXv2eBOxnNPQdJUsc9B0kLzm85L3/uOUiSOoaDJKnjYSUte0v9xJ60\nHBkOWhLGcYx6Pq9psOhn3ZIJhySbgP8KrAD+e1VdP+aWpCmdLHsrnlg+eS2JcEiyAvgM8FvAQeC+\nJLuq6tHxdnZy8jfqE2ccH7b+TDQXSyIcgPOBiap6EiDJTmAzYDjMg7/1SZqrpRIOa4Bnhh4fBN4x\npl6WFD/gJY3DUgmHWUmyFdjaHv4wyeMjhp0B/M3idTUvy6XXWfeZG05wJ9NbLusTFrHXef5Mlss6\nPWn6XIB/Y784m0FLJRwOAeuGHq9ttZ9SVTcDN0/3REn2VtXGhW3vxFguvdrnwlsuvdrnwloufcLS\n+RLcfcCGJGcnORW4HNg15p4k6aS1JPYcqupYkmuAOxlcyrq9qvaPuS1JOmktiXAAqKrdwO4FeKpp\nDzstMculV/tceMulV/tcWMulT1JV4+5BkrTELJVzDpKkJWRZhkOSdUnuTvJokv1JPjxizIVJXkqy\nr93+ZBy9tl6eSvJw62PviPlJcmOSiSQPJTlvDD3+w6F1tS/Jy0k+MmnMWNZpku1Jnk/yyFDt9CR7\nkhxo96umWHZLG3MgyZYx9Plfkny3/Vy/kuS0KZaddhtZpF6vS3Jo6Od76RTLbkryeNtet42hz9uG\nenwqyb4pll20dTrVZ9JS3E5nraqW3Q04CzivTb8J+GvgnEljLgS+Ou5eWy9PAWdMM/9S4OtAgAuA\ne8fc7wrgWeAXl8I6BX4TOA94ZKj2n4FtbXobcMOI5U4Hnmz3q9r0qkXu8yJgZZu+YVSfs9lGFqnX\n64B/P4tt4wngl4BTgQcn/9s70X1Omv8p4E/GvU6n+kxaitvpbG/Lcs+hqg5X1QNt+gfAYwy+Zb1c\nbQZurYF7gNOSnDXGft4NPFFVT4+xh1dV1TeBo5PKm4EdbXoHcNmIRS8G9lTV0ap6EdgDbFrMPqvq\nG1V1rD28h8F3eMZuinU6G6/+qZuq+glw/E/dnBDT9ZkkwPuBL5yo15+taT6Tltx2OlvLMhyGJVkP\nvB24d8TsX0/yYJKvJ3nbojb20wr4RpL727e8Jxv150PGGXaXM/U/uKWyTs+sqsNt+lngzBFjltp6\n/V0Ge4ijzLSNLJZr2iGw7VMcAllK6/SfAs9V1YEp5o9lnU76TFqO2ymwzMMhyRuBLwEfqaqXJ81+\ngMFhkV8F/gz4X4vd35B3VtV5wCXA1Ul+c4y9TKt9CfG3gf85YvZSWqevqsG++ZK+7C7JHwPHgM9P\nMWQpbCM3AW8FzgUOMzhks5RdwfR7DYu+Tqf7TFoO2+mwZRsOSU5h8EP4fFV9efL8qnq5qn7YpncD\npyQ5Y5HbPN7LoXb/PPAVBrvmw2b150MWySXAA1X13OQZS2mdAs8dP/TW7p8fMWZJrNck/xb4F8C/\naR8QnVlsIydcVT1XVa9U1d8Cn52ih6WyTlcC/xK4baoxi71Op/hMWjbb6WTLMhzascZbgMeq6tNT\njPn7bRxJzmfwXl9YvC5f7eMNSd50fJrBCcpHJg3bBVzZrlq6AHhpaFd0sU3529hSWafNLuD4VR1b\ngDtGjLkTuCjJqnaI5KJWWzQZ/CdW/wH47ar60RRjZrONnHCTznO9d4oelsqfuvnnwHer6uComYu9\nTqf5TFoW2+lI4z4jPpcb8E4Gu2cPAfva7VLgg8AH25hrgP0Mrqa4B/gnY+r1l1oPD7Z+/rjVh3sN\ng//s6AngYWDjmHp9A4MP+58fqo19nTIIq8PA/2VwPPYq4M3AXcAB4K+A09vYjQz+J8Hjy/4uMNFu\nHxhDnxMMjicf307/oo39BWD3dNvIGHr9y7b9PcTgQ+2syb22x5cyuBrniRPd66g+W/1zx7fLobFj\nW6fTfCYtue10tje/IS1J6izLw0qSpBPLcJAkdQwHSVLHcJAkdQwHSVLHcJAkdQwHSVLHcJAkdf4f\nnhtZkAPlTW0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa0efab87b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('The median accuracy is: {}'.format(average_accuracy.median(axis=1)[0]))\n",
    "print('The mean accuracy is:   {}'.format(average_accuracy.mean(axis=1)[0]))\n",
    "plt.hist(correct['num_correct'], bins=21)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ALG1</th>\n",
       "      <th>ALG2</th>\n",
       "      <th>ALG3</th>\n",
       "      <th>ALG4</th>\n",
       "      <th>ALG5</th>\n",
       "      <th>ALG6</th>\n",
       "      <th>ALG7</th>\n",
       "      <th>ALG8</th>\n",
       "      <th>ALG9</th>\n",
       "      <th>ALG10</th>\n",
       "      <th>...</th>\n",
       "      <th>ALG12</th>\n",
       "      <th>ALG13</th>\n",
       "      <th>ALG14</th>\n",
       "      <th>ALG15</th>\n",
       "      <th>ALG16</th>\n",
       "      <th>ALG17</th>\n",
       "      <th>ALG18</th>\n",
       "      <th>ALG19</th>\n",
       "      <th>ALG20</th>\n",
       "      <th>ALG21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.890491</td>\n",
       "      <td>0.928382</td>\n",
       "      <td>0.997109</td>\n",
       "      <td>0.928055</td>\n",
       "      <td>0.999109</td>\n",
       "      <td>0.131473</td>\n",
       "      <td>0.871055</td>\n",
       "      <td>0.174564</td>\n",
       "      <td>0.927764</td>\n",
       "      <td>0.957655</td>\n",
       "      <td>...</td>\n",
       "      <td>0.926127</td>\n",
       "      <td>0.924655</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.885</td>\n",
       "      <td>0.929709</td>\n",
       "      <td>0.923873</td>\n",
       "      <td>0.999109</td>\n",
       "      <td>0.983309</td>\n",
       "      <td>0.996382</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ALG1      ALG2      ALG3      ALG4      ALG5      ALG6      ALG7  \\\n",
       "0  0.890491  0.928382  0.997109  0.928055  0.999109  0.131473  0.871055   \n",
       "\n",
       "       ALG8      ALG9     ALG10    ...        ALG12     ALG13  ALG14  ALG15  \\\n",
       "0  0.174564  0.927764  0.957655    ...     0.926127  0.924655    1.0    1.0   \n",
       "\n",
       "   ALG16     ALG17     ALG18     ALG19     ALG20     ALG21  \n",
       "0  0.885  0.929709  0.923873  0.999109  0.983309  0.996382  \n",
       "\n",
       "[1 rows x 21 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute accuracy of each algorithm\n",
    "pd.DataFrame(train_data_unlabeled.mean()).transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Design of Project\n",
    "Our initial goal was to build a regression model whose input is an MNIST image, and whose output predicts the percentage of algorithms that would classify it correctly (PERCENT_CORRECT). From there, we would determine a threshold to classify these images as EASY or HARD to classify. The rationale was the assumption that certain features that lead to misclassification may appear to different degrees. That is, these are not binary features. As such, it seems that we would lose information if we were to just train on EASY/HARD labels rather than PERCENT_CORRECT.\n",
    "\n",
    "However, the regression model did not converge, and given our time/compute constraints, we opted to resort to the binary classification model. Our classifier is a two-layer MLP, with hidden dimensions 1024 and 128. The results of this are shown below.\n",
    "\n",
    "## Basic Classifier\n",
    "\n",
    "Here, we create a MLP that attempts to predict the percent of classifiers that correctly classified an image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data\n",
    "def aggregator(row):\n",
    "    return int(row.sum() > 18)\n",
    "\n",
    "train_x = mnist.train.images\n",
    "train_y = train_data_unlabeled.apply(aggregator, axis=1).reset_index().drop('ID', axis=1)\n",
    "train_y_one_hot = tf.Session().run(tf.one_hot(train_y, 2)).reshape((-1,2))\n",
    "\n",
    "val_x = mnist.validation.images\n",
    "val_y = val_data_unlabeled.apply(aggregator,axis=1).reset_index().drop('ID', axis=1)\n",
    "val_y_one_hot = tf.Session().run(tf.one_hot(val_y, 2)).reshape((-1,2))\n",
    "\n",
    "test_x = mnist.test.images\n",
    "test_y = test_data_unlabeled.apply(aggregator, axis=1).reset_index().drop('ID', axis=1)\n",
    "test_y_one_hot = tf.Session().run(tf.one_hot(test_y, 2)).reshape((-1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier = mlp.MLP(train_x, train_y_one_hot, './save', hidden_1=1024, hidden_2=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./save\n",
      "Optimization Finished!\n"
     ]
    }
   ],
   "source": [
    "classifier.train(training_epochs=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./save\n",
      "INFO:tensorflow:Restoring parameters from ./save\n",
      "INFO:tensorflow:Restoring parameters from ./save\n",
      "Train Accuracy: 0.7108727097511292\n",
      "Val Accuracy:   0.7368000149726868\n",
      "Test Accuracy:  0.670799970626831\n"
     ]
    }
   ],
   "source": [
    "train_acc = classifier.accuracy(train_x, train_y_one_hot)\n",
    "val_acc   = classifier.accuracy(val_x, val_y_one_hot)\n",
    "test_acc  = classifier.accuracy(test_x, test_y_one_hot)\n",
    "\n",
    "print('Train Accuracy: {}'.format(train_acc))\n",
    "print('Val Accuracy:   {}'.format(val_acc))\n",
    "print('Test Accuracy:  {}'.format(test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Future Direction\n",
    "We saw, in the analysis of the training data, that two algorithms, ALG14 and ALG15 consistently had the correct predictions. It follows that they contribute nothing to the learner. On the other hand, ALG6 obtained a 0.131 accuracy (note that guessing at random should obtain about 0.10 accuracy). This suggests that we should take these accuracies into account when generating the EASY/HARD classification. \n",
    "\n",
    "It is unsurprising if a classifier that is near random classifies an image incorrectly, and therefore, we should take that less into account when deciding when an image is EASY/HARD. Conversely, if an algorithm that is almost always correct errs, then we should give more weight to that error.\n",
    "\n",
    "In fact, generating EASY/HARD labels using the weighted accuracies may reflect more 'real' features in the data (e.g. reducing noise from poor/near-random classifiers).\n",
    "\n",
    "We also may consider using different representations of MNIST images. Similar to word embeddings, we can take the last hidden layer of the output of a CNN (trained on the original MNIST problem of classifying digits) as the representation of the image. This may allow relevant features to be more readily accessible and tied with the EASY/HARD labels as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
